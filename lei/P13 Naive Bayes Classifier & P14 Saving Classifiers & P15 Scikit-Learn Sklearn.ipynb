{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P13 Naive Bayes Classifier\n",
    "\n",
    "Now, separate our data into training and testing sets, and press go! The algorithm that we're going to use first is the Naive Bayes classifier. This is a pretty popular algorithm used in text classification, so it is only fitting that we try it out first. Before we can train and test our algorithm, however, we need to go ahead and split up the data into a training set and a testing set.\n",
    "\n",
    "You could train and test on the same dataset, but this would present you with some serious bias issues, so you should never train and test against the exact same data. To do this, since we've shuffled our data set, we'll assign the first 1,900 shuffled reviews, consisting of both positive and negative reviews, as the training set. Then, we can test against the last 100 to see how accurate we are.\n",
    "\n",
    "This is called supervised machine learning, because we're showing the machine data, and telling it \"hey, this data is positive,\" or \"this data is negative.\" Then, after that training is done, we show the machine some new data and ask the computer, based on what we taught the computer before, what the computer thinks the category of the new data is.\n",
    "\n",
    "We can split the data with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set that we'll train our classifier with\n",
    "training_set = featuresets[:1900]\n",
    "\n",
    "# set that we'll test against.\n",
    "testing_set = featuresets[1900:]\n",
    "\n",
    "# First we just simply are invoking the Naive Bayes classifier, then we go ahead and use .train() to train it all in one line\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### extera libs to support sklearn\n",
    "\n",
    "#pip install numpy\n",
    "#pip install scipy\n",
    "#pip install matplotlib\n",
    "#pip install scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 79.0\n"
     ]
    }
   ],
   "source": [
    "## Test Script\n",
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "#print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "\n",
    "# set that we'll train our classifier with\n",
    "training_set = featuresets[:1900]\n",
    "\n",
    "# set that we'll test against.\n",
    "testing_set = featuresets[1900:]\n",
    "\n",
    "# First we just simply are invoking the Naive Bayes classifier, then we go ahead and use .train() to train it all in one line\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   sucks = True              neg : pos    =      9.8 : 1.0\n",
      "                 miscast = True              neg : pos    =      8.6 : 1.0\n",
      "                 frances = True              pos : neg    =      8.3 : 1.0\n",
      "           unimaginative = True              neg : pos    =      8.3 : 1.0\n",
      "                  suvari = True              neg : pos    =      7.0 : 1.0\n",
      "                 idiotic = True              neg : pos    =      7.0 : 1.0\n",
      "                    mena = True              neg : pos    =      7.0 : 1.0\n",
      "              schumacher = True              neg : pos    =      7.0 : 1.0\n",
      "               atrocious = True              neg : pos    =      6.6 : 1.0\n",
      "                  turkey = True              neg : pos    =      6.6 : 1.0\n",
      "                obstacle = True              pos : neg    =      6.3 : 1.0\n",
      "                 singers = True              pos : neg    =      6.3 : 1.0\n",
      "                 kidding = True              neg : pos    =      6.3 : 1.0\n",
      "                  shoddy = True              neg : pos    =      6.3 : 1.0\n",
      "             silverstone = True              neg : pos    =      6.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this tells you is the ratio of occurences in negative to positive, or visa versa, for every word. So here, we can see that the term \"insulting\" appears 10.6 more times as often in negative reviews as it does in positive reviews. Ludicrous, 10.1.\n",
    "\n",
    "Now, let's say you were totally content with your results, and you wanted to move forward, maybe using this classifier to predict things right now. It would be very impractical to train the classifier, and retrain it every time you needed to use it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P14 Saving Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training classifiers and machine learning algorithms can take a very long time, especially if you're training against a larger data set. Ours is actually pretty small. Can you imagine having to train the classifier every time you wanted to fire it up and use it? What horror! Instead, what we can do is use the Pickle module to go ahead and serialize our classifier object, so that all we need to do is load that file in real quick.\n",
    "\n",
    "So, how do we do this? The first step is to save the object. To do this, first you need to import pickle at the top of your script, then, after you have trained with .train() the classifier, you can then call the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This opens up a pickle file, preparing to write in bytes some data. \n",
    "#Then, we use pickle.dump() to dump the data. The first parameter to pickle.dump() is what are you dumping, \n",
    "#the second parameter is where are you dumping it.\n",
    "\n",
    "#After that, we close the file as we're supposed to, and that is that, we now have a pickled, or serialized, \n",
    "# object saved in our script's directory!\n",
    "\n",
    "save_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, how would we go about opening and using this classifier? The .pickle file is a serialized object, all we need to do now is read it into memory, which will be about as quick as reading any other ordinary file. To do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 80.0\n"
     ]
    }
   ],
   "source": [
    "classifier_f = open(\"naivebayes.pickle\", \"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we do a very similar process. We open the file to read as bytes. Then, we use pickle.load() to load the file, and we save the data to the classifier variable. Then we close the file, and that is that. We now have the same classifier object as before!\n",
    "\n",
    "Now, we can use this object, and we no longer need to train our classifier every time we wanted to use it to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P15 Scikit-Learn Sklearn\n",
    "the people behind NLTK forsaw the value of incorporating the sklearn module into the NLTK classifier methodology. As such, they created the SklearnClassifier API of sorts. To use that, you just need to import it like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB accuracy percent: 0.83\n",
      "BernoulliNB accuracy percent: 0.78\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MultinomialNB accuracy percent:\",nltk.classify.accuracy(MNB_classifier, testing_set))\n",
    "\n",
    "BNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB accuracy percent:\",nltk.classify.accuracy(BNB_classifier, testing_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bring in some more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 79.0\n",
      "Most Informative Features\n",
      "                  regard = True              pos : neg    =     11.0 : 1.0\n",
      "                   sucks = True              neg : pos    =     10.6 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.6 : 1.0\n",
      "                  annual = True              pos : neg    =      9.0 : 1.0\n",
      "             silverstone = True              neg : pos    =      7.7 : 1.0\n",
      "              schumacher = True              neg : pos    =      7.0 : 1.0\n",
      "                  suvari = True              neg : pos    =      7.0 : 1.0\n",
      "           unimaginative = True              neg : pos    =      7.0 : 1.0\n",
      "                  shoddy = True              neg : pos    =      7.0 : 1.0\n",
      "                    mena = True              neg : pos    =      7.0 : 1.0\n",
      "                  neatly = True              pos : neg    =      7.0 : 1.0\n",
      "               atrocious = True              neg : pos    =      6.6 : 1.0\n",
      "                 kidding = True              neg : pos    =      6.3 : 1.0\n",
      "                  turkey = True              neg : pos    =      6.3 : 1.0\n",
      "                 cunning = True              pos : neg    =      6.3 : 1.0\n",
      "MNB_classifier accuracy percent: 83.0\n",
      "BernoulliNB_classifier accuracy percent: 78.0\n",
      "LogisticRegression_classifier accuracy percent: 74.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python363\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 74.0\n",
      "SVC_classifier accuracy percent: 73.0\n",
      "LinearSVC_classifier accuracy percent: 74.0\n",
      "NuSVC_classifier accuracy percent: 74.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(training_set)\n",
    "print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see SVC is wrong more often than it is right out of the gate, so we should probably dump that one. But then what? The next thing we can try is to use all of these algorithms at once. To do this, we can create another classifier, and make the result of that classifier based on what the other algorithms said. Sort of like a voting system, so we'll just need an odd number of algorithms. That's what we'll be talking about in the next tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
