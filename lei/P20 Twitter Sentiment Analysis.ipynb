{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P20 Twitter Sentiment Analysis\n",
    "\n",
    "Now that we have a sentiment analysis module, we can apply it to just about any text, but preferrably short bits of text, like from Twitter! To do this, we're going to combine this tutorial with the Twitter streaming API tutorial.\n",
    "\n",
    "The initial code from that tutorial is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "\n",
    "#consumer key, consumer secret, access token, access secret.\n",
    "ckey=\"fsdfasdfsafsffa\"\n",
    "csecret=\"asdfsadfsadfsadf\"\n",
    "atoken=\"asdf-aassdfs\"\n",
    "asecret=\"asdfsadfsdafsdafs\"\n",
    "\n",
    "class listener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "        print(data)\n",
    "        return(True)\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print status\n",
    "\n",
    "auth = OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)\n",
    "\n",
    "twitterStream = Stream(auth, listener())\n",
    "twitterStream.filter(track=[\"car\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is enough to print out all of the data for the streaming live tweets that contain the term \"car.\" We can use the json module to load the data var with json.loads(data), and then we can reference the tweet specifically with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = all_data[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a tweet, we can easily pass this through our sentiment_mod module!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ba6c80c9ea20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtweepy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtweepy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOAuthHandler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreaming\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStreamListener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msentiment_mod\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import sentiment_mod as s\n",
    "\n",
    "#consumer key, consumer secret, access token, access secret.\n",
    "ckey=\"asdfsafsafsaf\"\n",
    "csecret=\"asdfasdfsadfsa\"\n",
    "atoken=\"asdfsadfsafsaf-asdfsaf\"\n",
    "asecret=\"asdfsadfsadfsadfsadfsad\"\n",
    "\n",
    "from twitterapistuff import *\n",
    "\n",
    "class listener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "        \n",
    "        all_data = json.loads(data)\n",
    "        \n",
    "        tweet = all_data[\"text\"]\n",
    "        sentiment_value, confidence = s.sentiment(tweet)\n",
    "        print(tweet, sentiment_value, confidence)\n",
    "        \n",
    "        if confidence*100 >= 80:\n",
    "            output = open(\"twitter-out.txt\",\"a\")\n",
    "            output.write(sentiment_value)\n",
    "            output.write('\\n')\n",
    "            output.close()\n",
    "                \n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "auth = OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)\n",
    "\n",
    "twitterStream = Stream(auth, listener())\n",
    "twitterStream.filter(track=[\"happy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with that, we're also saving the results to an output file, twitter-out.txt.\n",
    "\n",
    "Next, what data analysis would be complete without graphs? Let's combine yet another tutorial with this one to make a live streaming graph from the sentiment analysis on the Twitter API!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
