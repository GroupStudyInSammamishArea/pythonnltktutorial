{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 20\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                            remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_samples = dataset.data[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle_data(filename):\n",
    "    file = open(filename, \"rb\")\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "    return data\n",
    "\n",
    "def pickle_data(data, filename):\n",
    "    file = open(filename, \"wb\")\n",
    "    pickle.dump(data, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_data(dataset, \"20newsgroups.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iambj\\AppData\\Local\\conda\\conda\\envs\\nltk\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=5,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=1, n_topics=20, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, \n",
    "                                max_features=n_features, \n",
    "                                stop_words='english')\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5, \n",
    "                               learning_method='online', learning_offset=5,\n",
    "                               random_state=0)\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well i'm not sure about the story nad it did seem biased. What\\nI disagree with is your statement that the U.S. Media is out to\\nruin Israels reputation. That is rediculous. The U.S. media is\\nthe most pro-israeli media in the world. Having lived in Europe\\nI realize that incidences such as the one described in the\\nletter have occured. The U.S. media as a whole seem to try to\\nignore them. The U.S. is subsidizing Israels existance and the\\nEuropeans are not (at least not to the same degree). So I think\\nthat might be a reason they report more clearly on the\\natrocities.\\n\\tWhat is a shame is that in Austria, daily reports of\\nthe inhuman acts commited by Israeli soldiers and the blessing\\nreceived from the Government makes some of the Holocaust guilt\\ngo away. After all, look how the Jews are treating other races\\nwhen they got power. It is unfortunate.\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: edu com mail send list cs message uk ac sun navy mit org stuff soon news address article rules request\n",
      "Topic #1: mr bios 000 armenian armenians home turkish local like bus water numbers rate hot azerbaijan control dot equipment don armenia\n",
      "Topic #2: year years oil hit team driving night runs defense leafs run better late sold james air hope player start pretty\n",
      "Topic #3: card 00 car new engine power drivers driver sale monitor apple computer performance price gas video offer software brake sell\n",
      "Topic #4: health hiv aids disease medical care display information research national study drug 1993 april page new service cost public need\n",
      "Topic #5: israel win jews men attacks israeli able text policy soldiers conference members allow women jewish blood different mike people small\n",
      "Topic #6: game play team greek opinions players mark goal pittsburgh new nhl hockey eric win games player early got playing bob\n",
      "Topic #7: 500 board bike car cars color insurance model license looking buy new safety costs buying figure higher models recommend interested\n",
      "Topic #8: problem window time matter post using experience like know isn trouble said make recently does tried printer good sounds quality\n",
      "Topic #9: space new church earth power moon science president years probe energy surface lunar press time mission sin launch designed weapon\n",
      "Topic #10: 55 17 26 23 11 windows 16 22 vs 15 24 32 gm 28 18 20 37 21 25 30\n",
      "Topic #11: 10 12 93 11 19 14 data 13 university period 20 15 16 1993 31 image pp images ca 18\n",
      "Topic #12: points food season black division games toronto allowed won teams regular played probably 1992 series goes added argument best world\n",
      "Topic #13: people said children went did left called dead came years happened didn asked house atheism old started later ago woman\n",
      "Topic #14: file ftp version graphics windows files available software pc server pub dos machines package faq program type unix comments support\n",
      "Topic #15: key chip government public use keys encryption clipper private security used communications encrypted secure phone standard message media nsa input\n",
      "Topic #16: law state police government section gun crime military rights self weapons firearm population person use guns laws dangerous states control\n",
      "Topic #17: drive hard disk drives scsi floppy feature controller cubs pin cable connector power shots heads run going running note didn\n",
      "Topic #18: use thanks know like need good does want bit time using rom read new work used don systems high way\n",
      "Topic #19: just don people think like know god say way does really good make time ve want right going doesn things\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
